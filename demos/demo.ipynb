{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iKnow Demo Notebook\n",
    "\n",
    "This Jupyter notebook bundles a handful of simple demos for the [iKnow NLP engine](https://github.com/intersystems/iknow):\n",
    "\n",
    "1. [The Basics](#The-Basics)\n",
    "1. [Indexing Text](#Indexing-Text)\n",
    "1. [Highlighting](#Highlighting)\n",
    "1. [Feature Engineering](#Feature-Engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Basics\n",
    "\n",
    "The following paragraph just loads the iKnow engine and prints the set of supported languages.\n",
    "\n",
    "If you haven't already, please run ```pip install iknowpy``` first to retrieve the latest version from PyPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en', 'cs', 'ru', 'ja', 'uk', 'sv', 'nl', 'fr', 'pt', 'es', 'de'}\n"
     ]
    }
   ],
   "source": [
    "import iknowpy\n",
    "\n",
    "# initialize the engine\n",
    "iknow = iknowpy.iKnowEngine()\n",
    "\n",
    "# display supported languages\n",
    "print(iknow.get_languages_set())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing Text\n",
    "\n",
    "The `index()` function is the main entry point into the engine, taking a text string and language code (any of the ones printed in the previous command). An optional third argument helps you to the full trace output in case you are debugging language model work or just very interested :-)\n",
    "\n",
    "Upon the method returning, it will have its `m_index` array populated with the indexing results for the supplied text string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentences': [{'entities': [{'type': 'Concept', 'offset_start': 0, 'offset_stop': 17, 'index': 'belgian chocolate', 'dominance_value': 1000.0, 'entity_id': 1}, {'type': 'Relation', 'offset_start': 18, 'offset_stop': 20, 'index': 'is', 'dominance_value': 333.0, 'entity_id': 2}, {'type': 'Concept', 'offset_start': 21, 'offset_stop': 40, 'index': 'suprisingly popular', 'dominance_value': 1000.0, 'entity_id': 3}, {'type': 'Relation', 'offset_start': 41, 'offset_stop': 44, 'index': 'for', 'dominance_value': 333.0, 'entity_id': 4}, {'type': 'NonRelevant', 'offset_start': 45, 'offset_stop': 46, 'index': 'a', 'dominance_value': 0.0, 'entity_id': 0}, {'type': 'Concept', 'offset_start': 47, 'offset_stop': 54, 'index': 'country', 'dominance_value': 500.0, 'entity_id': 5}, {'type': 'Relation', 'offset_start': 55, 'offset_stop': 72, 'index': \"that doesn't have\", 'dominance_value': 1000.0, 'entity_id': 6}, {'type': 'NonRelevant', 'offset_start': 73, 'offset_stop': 76, 'index': 'any', 'dominance_value': 0.0, 'entity_id': 0}, {'type': 'Concept', 'offset_start': 77, 'offset_stop': 89, 'index': 'cocoa trees', 'dominance_value': 1000.0, 'entity_id': 7}], 'sent_attributes': [{'type': 'Negation', 'offset_start': 60, 'offset_stop': 67, 'marker': \"doesn't\", 'value': '', 'unit': '', 'value2': '', 'unit2': '', 'entity_ref': 6}], 'path': [0, 1, 2, 3, 5, 6, 8], 'path_attributes': [{'type': 'Negation', 'pos': 4, 'span': 3}]}], 'proximity': [((5, 7), 64), ((1, 3), 64), ((3, 5), 64), ((3, 7), 42), ((1, 5), 42), ((1, 7), 32)]}\n"
     ]
    }
   ],
   "source": [
    "# this is the main API function, just taking text and a language code\n",
    "iknow.index(\"Belgian chocolate is suprisingly popular for a country that doesn't have any cocoa trees.\",\"en\")\n",
    "\n",
    "# now we can look at the raw output\n",
    "print(iknow.m_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other modules such as `pprint` help render this in a slightly more readable way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'proximity': [ ((5, 7), 64),\n",
      "                 ((1, 3), 64),\n",
      "                 ((3, 5), 64),\n",
      "                 ((3, 7), 42),\n",
      "                 ((1, 5), 42),\n",
      "                 ((1, 7), 32)],\n",
      "  'sentences': [ { 'entities': [ { 'dominance_value': 1000.0,\n",
      "                                   'entity_id': 1,\n",
      "                                   'index': 'belgian chocolate',\n",
      "                                   'offset_start': 0,\n",
      "                                   'offset_stop': 17,\n",
      "                                   'type': 'Concept'},\n",
      "                                 { 'dominance_value': 333.0,\n",
      "                                   'entity_id': 2,\n",
      "                                   'index': 'is',\n",
      "                                   'offset_start': 18,\n",
      "                                   'offset_stop': 20,\n",
      "                                   'type': 'Relation'},\n",
      "                                 { 'dominance_value': 1000.0,\n",
      "                                   'entity_id': 3,\n",
      "                                   'index': 'suprisingly popular',\n",
      "                                   'offset_start': 21,\n",
      "                                   'offset_stop': 40,\n",
      "                                   'type': 'Concept'},\n",
      "                                 { 'dominance_value': 333.0,\n",
      "                                   'entity_id': 4,\n",
      "                                   'index': 'for',\n",
      "                                   'offset_start': 41,\n",
      "                                   'offset_stop': 44,\n",
      "                                   'type': 'Relation'},\n",
      "                                 { 'dominance_value': 0.0,\n",
      "                                   'entity_id': 0,\n",
      "                                   'index': 'a',\n",
      "                                   'offset_start': 45,\n",
      "                                   'offset_stop': 46,\n",
      "                                   'type': 'NonRelevant'},\n",
      "                                 { 'dominance_value': 500.0,\n",
      "                                   'entity_id': 5,\n",
      "                                   'index': 'country',\n",
      "                                   'offset_start': 47,\n",
      "                                   'offset_stop': 54,\n",
      "                                   'type': 'Concept'},\n",
      "                                 { 'dominance_value': 1000.0,\n",
      "                                   'entity_id': 6,\n",
      "                                   'index': \"that doesn't have\",\n",
      "                                   'offset_start': 55,\n",
      "                                   'offset_stop': 72,\n",
      "                                   'type': 'Relation'},\n",
      "                                 { 'dominance_value': 0.0,\n",
      "                                   'entity_id': 0,\n",
      "                                   'index': 'any',\n",
      "                                   'offset_start': 73,\n",
      "                                   'offset_stop': 76,\n",
      "                                   'type': 'NonRelevant'},\n",
      "                                 { 'dominance_value': 1000.0,\n",
      "                                   'entity_id': 7,\n",
      "                                   'index': 'cocoa trees',\n",
      "                                   'offset_start': 77,\n",
      "                                   'offset_stop': 89,\n",
      "                                   'type': 'Concept'}],\n",
      "                   'path': [0, 1, 2, 3, 5, 6, 8],\n",
      "                   'path_attributes': [ { 'pos': 4,\n",
      "                                          'span': 3,\n",
      "                                          'type': 'Negation'}],\n",
      "                   'sent_attributes': [ { 'entity_ref': 6,\n",
      "                                          'marker': \"doesn't\",\n",
      "                                          'offset_start': 60,\n",
      "                                          'offset_stop': 67,\n",
      "                                          'type': 'Negation',\n",
      "                                          'unit': '',\n",
      "                                          'unit2': '',\n",
      "                                          'value': '',\n",
      "                                          'value2': ''}]}]}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "pp.pprint(iknow.m_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can of course also loop through the output and print the most important parts of the parsing ourselves. In the simple example below, we're printing the normalized *index* value of each sentence part, along with its role:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: belgian chocolate\n",
      "Relation: is\n",
      "Concept: suprisingly popular\n",
      "Relation: for\n",
      "NonRelevant: a\n",
      "Concept: country\n",
      "Relation: that doesn't have\n",
      "NonRelevant: any\n",
      "Concept: cocoa trees\n"
     ]
    }
   ],
   "source": [
    "# print basic parsing output\n",
    "for s in iknow.m_index['sentences']:\n",
    "    for e in s['entities']:\n",
    "        print(e['type']+': '+e['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highlighting\n",
    "\n",
    "The following snippet pulls in `colorama`, which is a convenient package for highlighting command-line output (that also works in most notebook apps). There are fancier packages with more options, but this one is universal across UNIX and Windows.\n",
    "\n",
    "This time we'll leverage both the entity role and the *Negation* and *Certainty* attributes iKnow detects in natural language text. We'll create this as a function so we can easily reuse it in further examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use colorama to make it look nicer\n",
    "from colorama import Fore, Style\n",
    "\n",
    "#from colorama import init\n",
    "#init() # init colorama - only when running outside notebook\n",
    "\n",
    "def highlight(text, language=\"en\", iknow=iknowpy.iKnowEngine()):\n",
    "    \n",
    "    iknow.index(text, language)\n",
    "    \n",
    "    for s in iknow.m_index['sentences']:\n",
    "        \n",
    "        # first figure out where negation spans are and tag those entities\n",
    "        for a in s['path_attributes']:\n",
    "            \n",
    "            # path attributes are expressed as positions within s['path'],\n",
    "            # which in turn keys into the s['entities'] array\n",
    "            for ent in range(s['path'][a['pos']], \n",
    "                             s['path'][a['pos']+a['span']-1]+1):\n",
    "                if a['type']==\"Negation\":\n",
    "                    s['entities'][ent]['colour'] = Fore.RED\n",
    "                if a['type']==\"Certainty\":\n",
    "                    s['entities'][ent]['colour'] = Fore.CYAN\n",
    "                    \n",
    "        for e in s['entities']:\n",
    "            colour = Fore.BLACK\n",
    "            style = Style.NORMAL\n",
    "            \n",
    "            if \"colour\" in e:\n",
    "                colour = e[\"colour\"]\n",
    "                \n",
    "            if (e['type'] == 'Concept'):\n",
    "                style = Style.BRIGHT\n",
    "            if (e['type'] == 'NonRelevant') | (e['type'] == 'PathRelevant'):\n",
    "                style = Style.DIM\n",
    "                \n",
    "            print(colour + style + text[e['offset_start']:e['offset_stop']], end=' ')\n",
    "            \n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30m\u001b[2mThe \u001b[31m\u001b[1mquick brown fox \u001b[31m\u001b[22mdid not manage to jump over \u001b[31m\u001b[2mthe \u001b[31m\u001b[1mlazy dog, \u001b[30m\u001b[22mbut still managed to catch \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mcurry chicken. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "highlight(\"The quick brown fox did not manage to jump over the lazy dog, but still managed to catch the curry chicken.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as a final part, we'll use this function to render a quick grab of an international news feed using the `feedparser` package and quickly spot uncertain or negated phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White House senior adviser Stephen Miller tests positive and several military leaders quarantine.\n",
      "The co-founder of Van Halen is remembered as a \"Guitar God\" following his death from cancer aged 65.\n",
      "The president and Democratic leader Nancy Pelosi trade blame for the collapse of negotiations.\n",
      "The H-1B visa has mostly been used by Indian and Chinese technology workers to fill skills gaps.\n",
      "The social network is deleting groups, pages and accounts linked to the conspiracy theory movement.\n",
      "A grand jury indicts the streaming service for the alleged \"lewd exhibition\" of under-age children.\n",
      "The American artist was best known for the 1972 hit I Can See Clearly Now.\n",
      "A congressional report from House Democrats recommends changes that could lead to breaking up the companies.\n",
      "The US has updated its guidance to reflect how the virus can linger in the air, sometimes for hours.\n",
      "The Democratic presidential nominee criticises Donald Trump for downplaying Covid-19.\n",
      "The US secretary of state met foreign ministers from Japan, India and Australia.\n",
      "The anti-virus creator faces extradition to the US for allegedly failing to file tax returns.\n",
      "Twitter hid an identical post saying virus was less lethal than the flu season in most populations.\n",
      "Jonathan Price was killed on Saturday while reportedly trying to break up a fight.\n",
      "A judge will look at the evidence but not until after the US has gone to the polls.\n",
      "The girl's family had accused the Canadian government of not doing enough to bring her back.\n",
      "Luxury suites, experimental drugs and how the president's VIP Covid treatment differs from the norm.\n",
      "From contested elections to to the electoral college, we answer the burning questions you sent us.\n",
      "The US president is telling Americans not to let Covid-19 control their lives. What do they think?\n",
      "Not usually considered a must-watch, this campaign's vice-presidential debate has taken on fresh importance.\n",
      "Trump fans are using TikTok to woo viewers over to his campaign despite his threat to ban the app.\n",
      "Training based on Ervin Staub's idea of bystander intervention is driving police reform in the US.\n",
      "US intelligence say the three are trying to interfere in November's vote but their aims differ.\n",
      "One couple among hundreds of Trump fans outside the hospital say they travelled all the way from Arizona.\n",
      "Friday 2 October began with President Trump announcing he had Covid-19. It ended with him in hospital.\n",
      "We asked some older US voters for their reactions to the president's Covid-19 diagnosis.\n",
      "It was a battle against time for Tony Vargas, who put personal tragedy aside to do what he thought was right.\n",
      "News outlets around the world report on the president's announcement with sympathy - but also blame.\n",
      "Americans saved at record rates when the pandemic started - but circumstances are changing.\n",
      "President Trump contracted Covid-19 after his close aide Hope Hicks tested positive.\n",
      "Aged 58, Bon Jovi has written his most political album yet. \"I had to bear witness,\" he tells the BBC.\n",
      "Fritz Pollard was the NFL's first black coach and its first black quarterback, but most American football fans have never heard of him.\n",
      "The rise of the US tech company has been shadowed by concerns about privacy and surveillance.\n",
      "Should we mute the microphones, find a better referee, or cancel them altogether?\n",
      "How did so many of President Trump's top team become infected with coronavirus?\n",
      "Biden's choice breaks barriers as she's the first black and Asian-American woman on a presidential ticket.\n",
      "More than 245 million Americans are eligible to vote but only a few will decide the outcome.\n",
      "In a choreographed and controversial return, Mr Trump took off his mask and walked into the White House.\n",
      "The US president will leave hospital with the \"identical understanding\" of Covid-19, says Michael Cohen.\n",
      "Speaking from the Walter Reed Medical Center, President Trump described his treatment as the 'real school'.\n",
      "What led to Dr Sean Conley being forced to clarify the president's treatment?\n",
      "President Trump says \"I'm starting to feel good,\" a day after being taken to hospital.\n",
      "The president tweeted his diagnosis early on Friday morning. Here's how American news reacted.\n",
      "Physicians looking after Donald Trump said they were \"cautiously optimistic, but he's doing great\".\n",
      "Jazz artists have been badly affected by the pandemic, with many forced to find alternative places to perform.\n",
      "Video shows Canadian police raiding an alleged operation at a lavish mansion in Ontario.\n",
      "Firefighters film their journey through the Glass Fire, one of many wildfires burning in California.\n",
      "These educators have zero tolerance for rule-breakers and name-calling - especially from presidential candidates.\n",
      "The scientists behind a microscopic \"walking\" robot hope their tech could one day be used against cancer.\n",
      "The president denies claims in the New York Times that he paid just $750 income tax in 2016 and 2017.\n",
      "A deputy went down the stairs head first trying to catch the defendant as he made a run for it.\n",
      "Watch what happened when California Police tried to pull over a speeding pick-up truck.\n",
      "A plaintiff, a student and a politician speak about the late Supreme Court justice's powerful influence.\n",
      "\"Well, we'll have to see what happens,\" the president tells a White House news conference.\n",
      "A law enforcement expert and a black runner analyse a police encounter that went wrong.\n",
      "The Supreme Court justice has died at the age of 87 after undergoing treatment for pancreatic cancer.\n",
      "President Trump said the justice 'lived an amazing life\" while rival Joe Biden praised her legal legacy.\n",
      "Matthew Shifrin took up the sport almost a year ago - with the help of a friend and a childhood toy.\n",
      "President Trump received a briefing about the wildfires burning across California,\n",
      "Four million acres have gone up in flames across the West Coast. Hundreds of thousands of people have been displaced so far.\n",
      "Over two million acres of land have burned in California, compared to 118,000 acres razed in 2019.\n"
     ]
    }
   ],
   "source": [
    "# now let's look at some real text and pick up an RSS feed\n",
    "import feedparser\n",
    "\n",
    "feed = feedparser.parse(\"http://newsrss.bbc.co.uk/rss/newsonline_world_edition/americas/rss.xml\")\n",
    "\n",
    "# feedparser helps us browse through the entries\n",
    "for entry in feed.entries:\n",
    "    print(entry.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30m\u001b[1mWhite House senior adviser Stephen Miller \u001b[30m\u001b[22mtests \u001b[30m\u001b[1mpositive \u001b[30m\u001b[22mand \u001b[30m\u001b[1mseveral military leaders quarantine. \n",
      "\n",
      "\u001b[30m\u001b[2mThe \u001b[30m\u001b[1mco-founder \u001b[30m\u001b[22mof \u001b[30m\u001b[1mVan Halen \u001b[30m\u001b[22mis remembered as \u001b[30m\u001b[2ma \u001b[30m\u001b[1m\"Guitar God\" \u001b[30m\u001b[22mfollowing \u001b[30m\u001b[2mhis \u001b[30m\u001b[1mdeath \u001b[30m\u001b[22mfrom \u001b[30m\u001b[1mcancer \u001b[30m\u001b[22maged \u001b[30m\u001b[1m65. \n",
      "\n",
      "\u001b[30m\u001b[2mThe \u001b[30m\u001b[1mpresident \u001b[30m\u001b[22mand \u001b[30m\u001b[1mDemocratic leader Nancy Pelosi trade blame \u001b[30m\u001b[22mfor \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mcollapse \u001b[30m\u001b[22mof \u001b[30m\u001b[1mnegotiations. \n",
      "\n",
      "\u001b[30m\u001b[2mThe \u001b[30m\u001b[1mH-1B visa \u001b[30m\u001b[22mhas mostly been used by \u001b[30m\u001b[1mIndian \u001b[30m\u001b[22mand \u001b[30m\u001b[1mChinese technology workers \u001b[30m\u001b[22mto fill \u001b[30m\u001b[1mskills gaps. \n",
      "\n",
      "\u001b[30m\u001b[2mThe \u001b[30m\u001b[1msocial network \u001b[30m\u001b[22mis deleting \u001b[30m\u001b[1mgroups, \u001b[30m\u001b[1mpages \u001b[30m\u001b[22mand \u001b[30m\u001b[1maccounts \u001b[30m\u001b[22mlinked to \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mconspiracy theory movement. \n",
      "\n",
      "\u001b[30m\u001b[2mA \u001b[30m\u001b[1mgrand jury \u001b[30m\u001b[22mindicts \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mstreaming service \u001b[30m\u001b[22mfor \u001b[30m\u001b[2mthe \u001b[30m\u001b[1malleged \"lewd exhibition\" \u001b[30m\u001b[22mof \u001b[30m\u001b[1munder-age children. \n",
      "\n",
      "\u001b[30m\u001b[2mThe \u001b[30m\u001b[1mAmerican artist \u001b[30m\u001b[22mwas best known for \u001b[30m\u001b[2mthe \u001b[30m\u001b[1m1972 \u001b[30m\u001b[22mhit \u001b[36m\u001b[2mI \u001b[36m\u001b[22mCan See Clearly \u001b[36m\u001b[2mNow. \n",
      "\n",
      "\u001b[30m\u001b[2mA \u001b[30m\u001b[1mcongressional report \u001b[30m\u001b[22mfrom \u001b[30m\u001b[1mHouse Democrats \u001b[30m\u001b[22mrecommends \u001b[30m\u001b[1mchanges \u001b[36m\u001b[22mthat could lead \u001b[30m\u001b[22mto breaking up \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mcompanies. \n",
      "\n",
      "\u001b[30m\u001b[2mThe \u001b[30m\u001b[1mUS \u001b[30m\u001b[22mhas updated \u001b[30m\u001b[2mits \u001b[30m\u001b[1mguidance \u001b[30m\u001b[22mto reflect how \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mvirus \u001b[30m\u001b[22mcan linger in \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mair, \u001b[30m\u001b[2msometimes \u001b[30m\u001b[22mfor \u001b[30m\u001b[1mhours. \n",
      "\n",
      "\u001b[30m\u001b[2mThe \u001b[30m\u001b[1mDemocratic presidential nominee \u001b[30m\u001b[22mcriticises \u001b[30m\u001b[1mDonald Trump \u001b[30m\u001b[22mfor \u001b[30m\u001b[1mdownplaying Covid-19. \n",
      "\n",
      "\u001b[30m\u001b[2mThe \u001b[30m\u001b[1mUS secretary of state \u001b[30m\u001b[22mmet \u001b[30m\u001b[1mforeign ministers \u001b[30m\u001b[22mfrom \u001b[30m\u001b[1mJapan, \u001b[30m\u001b[1mIndia \u001b[30m\u001b[22mand \u001b[30m\u001b[1mAustralia. \n",
      "\n",
      "\u001b[30m\u001b[2mThe \u001b[30m\u001b[1manti-virus creator \u001b[30m\u001b[22mfaces \u001b[30m\u001b[1mextradition \u001b[30m\u001b[22mto \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mUS \u001b[36m\u001b[22mfor allegedly failing to file \u001b[36m\u001b[1mtax returns. \n",
      "\n",
      "\u001b[30m\u001b[1mTwitter \u001b[30m\u001b[22mhid \u001b[30m\u001b[2man \u001b[30m\u001b[1midentical post saying virus \u001b[30m\u001b[22mwas \u001b[30m\u001b[1mless lethal \u001b[30m\u001b[22mthan \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mflu season \u001b[30m\u001b[22min \u001b[30m\u001b[1mmost populations. \n",
      "\n",
      "\u001b[30m\u001b[1mJonathan Price \u001b[30m\u001b[22mwas killed on \u001b[30m\u001b[1mSaturday \u001b[30m\u001b[22mwhile reportedly trying to break up \u001b[30m\u001b[2ma \u001b[30m\u001b[1mfight. \n",
      "\n",
      "\u001b[30m\u001b[2mA \u001b[30m\u001b[1mjudge \u001b[30m\u001b[22mwill look at \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mevidence \u001b[31m\u001b[22mbut not until after \u001b[31m\u001b[2mthe \u001b[31m\u001b[1mUS \u001b[31m\u001b[22mhas gone to \u001b[31m\u001b[2mthe \u001b[31m\u001b[1mpolls. \n",
      "\n",
      "\u001b[30m\u001b[2mThe \u001b[30m\u001b[1mgirl's family \u001b[30m\u001b[22mhad accused \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mCanadian government \u001b[31m\u001b[22mof not doing \u001b[31m\u001b[1menough \u001b[31m\u001b[22mto bring \u001b[31m\u001b[2mher \u001b[31m\u001b[1mback. \n",
      "\n",
      "\u001b[30m\u001b[1mLuxury suites, \u001b[30m\u001b[1mexperimental drugs \u001b[30m\u001b[22mand how \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mpresident's VIP Covid treatment \u001b[30m\u001b[22mdiffers from \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mnorm. \n",
      "\n",
      "\u001b[30m\u001b[22mFrom \u001b[30m\u001b[1mcontested elections \u001b[30m\u001b[22mto to \u001b[30m\u001b[2mthe \u001b[30m\u001b[1melectoral college, \u001b[30m\u001b[2mwe \u001b[30m\u001b[22manswer \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mburning questions \u001b[30m\u001b[2myou \u001b[30m\u001b[22msent \u001b[30m\u001b[2mus. \n",
      "\n",
      "\u001b[30m\u001b[2mThe \u001b[30m\u001b[1mUS president \u001b[30m\u001b[22mis telling \u001b[31m\u001b[1mAmericans \u001b[31m\u001b[22mnot to let \u001b[31m\u001b[1mCovid-19 \u001b[31m\u001b[22mcontrol \u001b[31m\u001b[2mtheir \u001b[31m\u001b[1mlives. \n",
      "\n",
      "\u001b[30m\u001b[22mWhat do \u001b[30m\u001b[2mthey \u001b[30m\u001b[22mthink? \n",
      "\n",
      "\u001b[31m\u001b[22mNot \u001b[31m\u001b[2musually \u001b[31m\u001b[22mconsidered \u001b[31m\u001b[2ma \u001b[31m\u001b[1mmust-watch, \u001b[30m\u001b[2mthis \u001b[30m\u001b[1mcampaign's vice-presidential debate \u001b[30m\u001b[22mhas taken on \u001b[30m\u001b[1mfresh importance. \n",
      "\n",
      "\u001b[30m\u001b[1mTrump fans \u001b[30m\u001b[22mare using \u001b[30m\u001b[1mTikTok \u001b[30m\u001b[22mto \u001b[30m\u001b[1mwoo viewers \u001b[30m\u001b[22mover to \u001b[30m\u001b[2mhis \u001b[30m\u001b[1mcampaign \u001b[30m\u001b[22mdespite \u001b[30m\u001b[2mhis \u001b[30m\u001b[1mthreat \u001b[30m\u001b[22mto ban \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mapp. \n",
      "\n",
      "\u001b[30m\u001b[22mTraining based on \u001b[30m\u001b[1mErvin Staub's idea \u001b[30m\u001b[22mof \u001b[30m\u001b[1mbystander intervention \u001b[30m\u001b[22mis driving \u001b[30m\u001b[1mpolice reform \u001b[30m\u001b[22min \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mUS. \n",
      "\n",
      "\u001b[30m\u001b[1mUS intelligence \u001b[30m\u001b[22msay \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mthree \u001b[30m\u001b[22mare trying to interfere \u001b[30m\u001b[22min \u001b[30m\u001b[1mNovember's vote \u001b[30m\u001b[22mbut \u001b[30m\u001b[2mtheir \u001b[30m\u001b[1maims \u001b[30m\u001b[22mdiffer. \n",
      "\n",
      "\u001b[30m\u001b[1mOne couple \u001b[30m\u001b[22mamong \u001b[30m\u001b[1mhundreds of Trump fans \u001b[30m\u001b[22moutside \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mhospital \u001b[30m\u001b[22msay \u001b[30m\u001b[2mthey \u001b[30m\u001b[22mtravelled \u001b[30m\u001b[1mall the way \u001b[30m\u001b[22mfrom \u001b[30m\u001b[1mArizona. \n",
      "\n",
      "\u001b[30m\u001b[1mFriday 2 October \u001b[30m\u001b[22mbegan with \u001b[30m\u001b[1mPresident Trump \u001b[30m\u001b[22mannouncing \u001b[30m\u001b[2mhe \u001b[30m\u001b[22mhad \u001b[30m\u001b[1mCovid-19. \n",
      "\n",
      "\u001b[30m\u001b[2mIt \u001b[30m\u001b[22mended with \u001b[30m\u001b[2mhim \u001b[30m\u001b[22min \u001b[30m\u001b[1mhospital. \n",
      "\n",
      "\u001b[30m\u001b[2mWe \u001b[30m\u001b[22masked \u001b[30m\u001b[1msome older US voters \u001b[30m\u001b[22mfor \u001b[30m\u001b[2mtheir \u001b[30m\u001b[1mreactions \u001b[30m\u001b[22mto \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mpresident's Covid-19 diagnosis. \n",
      "\n",
      "\u001b[30m\u001b[2mIt \u001b[30m\u001b[22mwas \u001b[30m\u001b[2ma \u001b[30m\u001b[1mbattle \u001b[30m\u001b[22magainst \u001b[30m\u001b[1mtime \u001b[30m\u001b[22mfor \u001b[30m\u001b[1mTony Vargas, \u001b[30m\u001b[22mwho put \u001b[30m\u001b[1mpersonal tragedy \u001b[30m\u001b[22maside to do what \u001b[30m\u001b[2mhe \u001b[30m\u001b[22mthought was \u001b[30m\u001b[1mright. \n",
      "\n",
      "\u001b[30m\u001b[1mNews outlets \u001b[30m\u001b[22maround \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mworld report \u001b[30m\u001b[22mon \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mpresident's announcement \u001b[30m\u001b[22mwith \u001b[30m\u001b[1msympathy \u001b[30m\u001b[2m- \u001b[30m\u001b[22mbut also \u001b[30m\u001b[1mblame. \n",
      "\n",
      "\u001b[30m\u001b[1mAmericans \u001b[30m\u001b[22msaved at \u001b[30m\u001b[1mrecord \u001b[30m\u001b[22mrates when \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mpandemic \u001b[30m\u001b[22mstarted \u001b[30m\u001b[2m- \u001b[30m\u001b[22mbut \u001b[30m\u001b[1mcircumstances \u001b[30m\u001b[22mare changing. \n",
      "\n",
      "\u001b[30m\u001b[1mPresident Trump \u001b[30m\u001b[22mcontracted \u001b[30m\u001b[1mCovid-19 \u001b[30m\u001b[22mafter \u001b[30m\u001b[2mhis \u001b[30m\u001b[1mclose aide Hope Hicks \u001b[30m\u001b[22mtested \u001b[30m\u001b[1mpositive. \n",
      "\n",
      "\u001b[30m\u001b[22mAged \u001b[30m\u001b[1m58, \u001b[30m\u001b[1mBon Jovi \u001b[30m\u001b[22mhas written \u001b[30m\u001b[2mhis \u001b[30m\u001b[1mmost political album \u001b[30m\u001b[22myet. \n",
      "\n",
      "\u001b[30m\u001b[2m\"I \u001b[30m\u001b[22mhad to bear \u001b[30m\u001b[1mwitness,\" \u001b[30m\u001b[2mhe \u001b[30m\u001b[22mtells \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mBBC. \n",
      "\n",
      "\u001b[30m\u001b[1mFritz Pollard \u001b[30m\u001b[22mwas \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mNFL's first black coach \u001b[30m\u001b[22mand \u001b[30m\u001b[2mits \u001b[30m\u001b[1mfirst black quarterback, \u001b[30m\u001b[22mbut \u001b[31m\u001b[1mmost American football fans \u001b[31m\u001b[22mhave never heard of \u001b[31m\u001b[2mhim. \n",
      "\n",
      "\u001b[30m\u001b[2mThe \u001b[30m\u001b[1mrise \u001b[30m\u001b[22mof \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mUS tech company \u001b[30m\u001b[22mhas been shadowed by \u001b[30m\u001b[1mconcerns \u001b[30m\u001b[22mabout \u001b[30m\u001b[1mprivacy \u001b[30m\u001b[22mand \u001b[30m\u001b[1msurveillance. \n",
      "\n",
      "\u001b[30m\u001b[22mShould \u001b[30m\u001b[2mwe \u001b[30m\u001b[22mmute \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mmicrophones, \u001b[30m\u001b[22mfind \u001b[30m\u001b[2ma \u001b[30m\u001b[1mbetter referee, \u001b[30m\u001b[22mor cancel \u001b[30m\u001b[2mthem \u001b[30m\u001b[1maltogether? \n",
      "\n",
      "\u001b[30m\u001b[22mHow did \u001b[30m\u001b[1mso many \u001b[30m\u001b[22mof \u001b[30m\u001b[1mPresident Trump's top team \u001b[30m\u001b[22mbecome infected with \u001b[30m\u001b[1mcoronavirus? \n",
      "\n",
      "\u001b[30m\u001b[1mBiden's choice \u001b[30m\u001b[22mbreaks \u001b[30m\u001b[1mbarriers \u001b[30m\u001b[22mas \u001b[30m\u001b[2mshe \u001b[30m\u001b[22m's \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mfirst black \u001b[30m\u001b[22mand \u001b[30m\u001b[1mAsian-American woman \u001b[30m\u001b[22mon \u001b[30m\u001b[2ma \u001b[30m\u001b[1mpresidential ticket. \n",
      "\n",
      "\u001b[30m\u001b[1mMore than 245 million Americans \u001b[30m\u001b[22mare \u001b[30m\u001b[1meligible \u001b[30m\u001b[22mto vote but only \u001b[30m\u001b[2ma \u001b[30m\u001b[1mfew \u001b[30m\u001b[22mwill decide \u001b[30m\u001b[2mthe \u001b[30m\u001b[1moutcome. \n",
      "\n",
      "\u001b[30m\u001b[22mIn \u001b[30m\u001b[2ma \u001b[30m\u001b[1mchoreographed \u001b[30m\u001b[22mand \u001b[30m\u001b[1mcontroversial return, \u001b[30m\u001b[1mMr Trump \u001b[30m\u001b[22mtook off \u001b[30m\u001b[2mhis \u001b[30m\u001b[1mmask \u001b[30m\u001b[22mand walked into \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mWhite House. \n",
      "\n",
      "\u001b[30m\u001b[2mThe \u001b[30m\u001b[1mUS president \u001b[30m\u001b[22mwill leave \u001b[30m\u001b[1mhospital \u001b[30m\u001b[22mwith \u001b[30m\u001b[2mthe \u001b[30m\u001b[1m\"identical understanding\" \u001b[30m\u001b[22mof \u001b[30m\u001b[1mCovid-19, \u001b[30m\u001b[22msays \u001b[30m\u001b[1mMichael Cohen. \n",
      "\n",
      "\u001b[30m\u001b[22mSpeaking from \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mWalter Reed Medical Center, \u001b[30m\u001b[1mPresident Trump \u001b[30m\u001b[22mdescribed \u001b[30m\u001b[2mhis \u001b[30m\u001b[1mtreatment \u001b[30m\u001b[22mas \u001b[30m\u001b[2mthe \u001b[30m\u001b[1m'real school'. \n",
      "\n",
      "\u001b[30m\u001b[22mWhat led to \u001b[30m\u001b[1mDr Sean Conley \u001b[30m\u001b[22mbeing forced to clarify \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mpresident's treatment? \n",
      "\n",
      "\u001b[30m\u001b[1mPresident Trump \u001b[30m\u001b[22msays \u001b[30m\u001b[2m\"I \u001b[30m\u001b[22m'm starting to feel \u001b[30m\u001b[1mgood,\" \u001b[30m\u001b[2ma \u001b[30m\u001b[1mday \u001b[30m\u001b[22mafter being taken to \u001b[30m\u001b[1mhospital. \n",
      "\n",
      "\u001b[30m\u001b[2mThe \u001b[30m\u001b[1mpresident \u001b[30m\u001b[22mtweeted \u001b[30m\u001b[2mhis \u001b[30m\u001b[1mdiagnosis \u001b[30m\u001b[1mearly on Friday morning. \n",
      "\n",
      "\u001b[30m\u001b[2mHere \u001b[30m\u001b[22m's how \u001b[30m\u001b[1mAmerican news \u001b[30m\u001b[22mreacted. \n",
      "\n",
      "\u001b[30m\u001b[1mPhysicians \u001b[30m\u001b[22mlooking after \u001b[30m\u001b[1mDonald Trump \u001b[30m\u001b[22msaid \u001b[30m\u001b[2mthey \u001b[30m\u001b[22mwere \u001b[30m\u001b[1m\"cautiously optimistic, \u001b[30m\u001b[22mbut \u001b[30m\u001b[2mhe \u001b[30m\u001b[22m's doing \u001b[30m\u001b[1mgreat\". \n",
      "\n",
      "\u001b[30m\u001b[1mJazz artists \u001b[30m\u001b[22mhave been \u001b[30m\u001b[1mbadly affected \u001b[30m\u001b[22mby \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mpandemic, \u001b[30m\u001b[22mwith \u001b[30m\u001b[2mmany \u001b[30m\u001b[22mforced to find \u001b[30m\u001b[1malternative places \u001b[30m\u001b[22mto perform. \n",
      "\n",
      "\u001b[30m\u001b[1mVideo \u001b[30m\u001b[22mshows \u001b[30m\u001b[1mCanadian police \u001b[30m\u001b[22mraiding \u001b[30m\u001b[2man \u001b[30m\u001b[1malleged operation \u001b[30m\u001b[22mat \u001b[30m\u001b[2ma \u001b[30m\u001b[1mlavish mansion \u001b[30m\u001b[22min \u001b[30m\u001b[1mOntario. \n",
      "\n",
      "\u001b[30m\u001b[1mFirefighters \u001b[30m\u001b[22mfilm \u001b[30m\u001b[2mtheir \u001b[30m\u001b[1mjourney \u001b[30m\u001b[22mthrough \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mGlass Fire, \u001b[30m\u001b[1mone of many wildfires \u001b[30m\u001b[22mburning in \u001b[30m\u001b[1mCalifornia. \n",
      "\n",
      "\u001b[30m\u001b[2mThese \u001b[30m\u001b[1meducators \u001b[30m\u001b[22mhave \u001b[30m\u001b[1mzero tolerance \u001b[30m\u001b[22mfor \u001b[30m\u001b[1mrule-breakers \u001b[30m\u001b[22mand \u001b[30m\u001b[1mname-calling \u001b[30m\u001b[2m- \u001b[30m\u001b[22mespecially from \u001b[30m\u001b[1mpresidential candidates. \n",
      "\n",
      "\u001b[30m\u001b[2mThe \u001b[30m\u001b[1mscientists \u001b[30m\u001b[22mbehind \u001b[30m\u001b[2ma \u001b[30m\u001b[1mmicroscopic \"walking\" robot \u001b[30m\u001b[22mhope \u001b[36m\u001b[2mtheir \u001b[36m\u001b[1mtech \u001b[36m\u001b[22mcould \u001b[36m\u001b[1mone day \u001b[36m\u001b[22mbe used against \u001b[36m\u001b[1mcancer. \n",
      "\n",
      "\u001b[30m\u001b[2mThe \u001b[30m\u001b[1mpresident \u001b[30m\u001b[22mdenies \u001b[30m\u001b[1mclaims \u001b[30m\u001b[22min \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mNew York Times \u001b[30m\u001b[22mthat \u001b[30m\u001b[2mhe \u001b[30m\u001b[22mpaid \u001b[30m\u001b[1mjust $750 income tax \u001b[30m\u001b[22min \u001b[30m\u001b[1m2016 \u001b[30m\u001b[22mand \u001b[30m\u001b[1m2017. \n",
      "\n",
      "\u001b[30m\u001b[2mA \u001b[30m\u001b[1mdeputy \u001b[30m\u001b[22mwent down \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mstairs head \u001b[30m\u001b[2mfirst \u001b[30m\u001b[22mtrying to catch \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mdefendant \u001b[30m\u001b[22mas \u001b[30m\u001b[2mhe \u001b[30m\u001b[22mmade \u001b[30m\u001b[2ma \u001b[30m\u001b[1mrun \u001b[30m\u001b[22mfor \u001b[30m\u001b[2mit. \n",
      "\n",
      "\u001b[30m\u001b[1mWatch \u001b[30m\u001b[22mwhat happened when \u001b[30m\u001b[1mCalifornia Police \u001b[30m\u001b[22mtried to pull over \u001b[30m\u001b[2ma \u001b[30m\u001b[1mspeeding pick-up truck. \n",
      "\n",
      "\u001b[30m\u001b[2mA \u001b[30m\u001b[1mplaintiff, \u001b[30m\u001b[2ma \u001b[30m\u001b[1mstudent \u001b[30m\u001b[22mand \u001b[30m\u001b[2ma \u001b[30m\u001b[1mpolitician \u001b[30m\u001b[22mspeak about \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mlate Supreme Court justice's powerful influence. \n",
      "\n",
      "\u001b[30m\u001b[22m\"Well, \u001b[30m\u001b[2mwe \u001b[30m\u001b[22m'll have to see what happens,\" \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mpresident \u001b[30m\u001b[22mtells \u001b[30m\u001b[2ma \u001b[30m\u001b[1mWhite House news conference. \n",
      "\n",
      "\u001b[30m\u001b[2mA \u001b[30m\u001b[1mlaw enforcement expert \u001b[30m\u001b[22mand \u001b[30m\u001b[2ma \u001b[30m\u001b[1mblack runner \u001b[30m\u001b[22manalyse \u001b[30m\u001b[2ma \u001b[30m\u001b[1mpolice encounter \u001b[30m\u001b[22mthat went \u001b[30m\u001b[1mwrong. \n",
      "\n",
      "\u001b[30m\u001b[2mThe \u001b[30m\u001b[1mSupreme Court justice \u001b[30m\u001b[22mhas died at \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mage \u001b[30m\u001b[22mof \u001b[30m\u001b[1m87 \u001b[30m\u001b[22mafter undergoing \u001b[30m\u001b[1mtreatment \u001b[30m\u001b[22mfor \u001b[30m\u001b[1mpancreatic cancer. \n",
      "\n",
      "\u001b[30m\u001b[1mPresident Trump \u001b[30m\u001b[22msaid \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mjustice \u001b[30m\u001b[22m'lived \u001b[30m\u001b[2man \u001b[30m\u001b[1mamazing life\" \u001b[30m\u001b[22mwhile \u001b[30m\u001b[1mrival Joe Biden \u001b[30m\u001b[22mpraised \u001b[30m\u001b[2mher \u001b[30m\u001b[1mlegal legacy. \n",
      "\n",
      "\u001b[30m\u001b[1mMatthew Shifrin \u001b[30m\u001b[22mtook up \u001b[30m\u001b[2mthe \u001b[30m\u001b[1msport \u001b[30m\u001b[1malmost a year ago \u001b[30m\u001b[2m- \u001b[30m\u001b[22mwith \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mhelp \u001b[30m\u001b[22mof \u001b[30m\u001b[2ma \u001b[30m\u001b[1mfriend \u001b[30m\u001b[22mand \u001b[30m\u001b[2ma \u001b[30m\u001b[1mchildhood toy. \n",
      "\n",
      "\u001b[30m\u001b[1mPresident Trump \u001b[30m\u001b[22mreceived \u001b[30m\u001b[2ma \u001b[30m\u001b[1mbriefing \u001b[30m\u001b[22mabout \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mwildfires burning \u001b[30m\u001b[22macross \u001b[30m\u001b[1mCalifornia, \n",
      "\n",
      "\u001b[30m\u001b[1mFour million acres \u001b[30m\u001b[22mhave gone up in \u001b[30m\u001b[1mflames \u001b[30m\u001b[22macross \u001b[30m\u001b[2mthe \u001b[30m\u001b[1mWest Coast. \n",
      "\n",
      "\u001b[30m\u001b[1mHundreds of thousands of people \u001b[30m\u001b[22mhave been displaced \u001b[30m\u001b[2mso far. \n",
      "\n",
      "\u001b[30m\u001b[1mOver two million acres \u001b[30m\u001b[22mof \u001b[30m\u001b[1mland \u001b[30m\u001b[22mhave burned in \u001b[30m\u001b[1mCalifornia, \u001b[30m\u001b[22mcompared to \u001b[30m\u001b[1m118,000 acres \u001b[30m\u001b[22mrazed \u001b[30m\u001b[22min \u001b[30m\u001b[1m2019. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# and apply iKnow highlighting to it\n",
    "for entry in feed.entries:\n",
    "    highlight(entry.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "The following code sample leverages iKnow to refine text-based Feature Engineering by removing negated parts of a sentence. This is a little blunt as a general tactic and different types of problems (and text) require different approaches, but it makes for a clear demo.\n",
    "\n",
    "We'll leverage iKnow to scrub the input fed into skicit-learn's [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) class. You'll need to run `pip install sklearn` to load those libraries before running this paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: apology (was Re: Did US drive on the left?)\n",
      "From: aas7@po.CWRU.Edu (Andrew A. Spencer)\n",
      "Reply-To: aas7@po.CWRU.Edu (Andrew A. Spencer)\n",
      "Organization: Case Western Reserve University, Cleveland, OH (USA)\n",
      "NNTP-Posting-Host: slc5.ins.cwru.edu\n",
      "Lines: 54\n",
      "\n",
      "\n",
      "In a previous article, dh3q+@andrew.cmu.edu (\"Daniel U. Holbrook\") says:\n",
      "\n",
      ">>i'm guessing, but i believe in the twenties we probably drove mostly down\n",
      ">>cattle trails and in wagon ruts.  I am fairly sure that placement of the \n",
      ">>steering wheel was pretty much arbitrary to the company at that time.....\n",
      ">\n",
      ">By the 1920s, there was a very active \"good roads\" movement, which had\n",
      ">its origins actually in the 1890s during the bicycle craze, picked up\n",
      ">steam in the teens (witness the Linclon Highway Association, 1912 or so,\n",
      ">and the US highway support act (real name: something different) in 1916\n",
      ">that first pledged federal aid to states and counties to build decent\n",
      ">roads. Also, the experience of widespread use of trucks for domestic\n",
      ">transport during WW 1 convinced the government that good raods were\n",
      ">crucial to our national defense.  Anyway, by the 20s there were plenty\n",
      ">of good roads, at least around urban areas, and they were rapidly\n",
      ">expanding into the countryside.  This was the era, after all, of the\n",
      ">first auto touring fad, the motel, the auto camp ground, etc. Two good\n",
      ">books on the subject spring to mind - Warren Belasco \"America on the\n",
      ">Road\" (title may not be exact - author is) and another called \"The Devil\n",
      ">Wagon in God's Country\" author I forget.  Also, any of John Flink's  or\n",
      ">John Bell Rae's auto histories.\n",
      "\n",
      "i'm sorry, as i have never heard of any of this.  Guess they don't think\n",
      "it's important enough for a classroom, and i was going on what i've seen\n",
      "in pics.(some movies--real nice scource there, huh?)  I just always \n",
      "recall thinking that GOOD roads of asphalt didn't come around til the\n",
      "Interstate Hiway Act, or whatever they called it(60's?), and that wood and\n",
      "cobblestone roads were fairly rare up through the depression, except in\n",
      "overpopulated places like England and US cities.  Obviously netwisdom\n",
      "says i am wrong.\n",
      "\n",
      ">As to placement of the steering wheel being arbitrary, by the early\n",
      ">teens there were virtually no American cars that did not have the wheel\n",
      ">on the left.  In the early days, cars had the wheel on the left, on the\n",
      ">right, and even in the middle, as well as sometimes having a tiller\n",
      ">instead of a wheel.  This was standardized fairly early on, though I\n",
      ">don't know why.\n",
      "\n",
      "i knew it was almost always done, but i knew of no reason that it might not\n",
      "be done the other way by DeSoto for their car.  Seems like they had some\n",
      "other deviations from the norm too, at times :-)\n",
      "\n",
      ">Dan\n",
      ">dh3q@andrew.cmu.edu\n",
      ">Carnegie Mellon University\n",
      ">Applied History\n",
      ">\n",
      ">\"World history strides on from catastrophe to catastrophe, whether we\n",
      ">can comprehend and prove it or not.\"\n",
      ">               Oswald Spengler\n",
      "\n",
      "thanx for corrrecting me, and again, i aplogize for harebraned post.\n",
      "DREW\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = [\n",
    " 'rec.autos',\n",
    " 'misc.forsale',\n",
    " 'sci.med',\n",
    "]\n",
    "example = 12\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories, random_state=123)\n",
    "print(data_train.data[example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The role of the `CountVectorizer` is to transform an array of strings into a document-term matrix with one column for each word and word frequencies as the corresponding values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1773, 28948)\n",
      "Sample record, after transformation:\n",
      "  (0, 12282)\t3\n",
      "  (0, 10575)\t5\n",
      "  (0, 15327)\t2\n",
      "  (0, 25118)\t2\n",
      "  (0, 12068)\t5\n",
      "  (0, 26358)\t1\n",
      "  (0, 12836)\t5\n",
      "  (0, 27352)\t1\n",
      "  (0, 19440)\t1\n",
      "  (0, 27177)\t2\n",
      "  (0, 16428)\t1\n",
      "  (0, 13410)\t2\n",
      "  (0, 19198)\t12\n",
      "  (0, 25977)\t8\n",
      "  (0, 26044)\t4\n",
      "  (0, 15454)\t1\n",
      "  (0, 10114)\t2\n",
      "  (0, 22561)\t1\n",
      "  (0, 19298)\t9\n",
      "  (0, 17324)\t1\n",
      "  (0, 4469)\t12\n",
      "  (0, 25984)\t34\n",
      "  (0, 4347)\t2\n",
      "  (0, 26294)\t8\n",
      "  (0, 11845)\t2\n",
      "  :\t:\n",
      "  (0, 15781)\t2\n",
      "  (0, 4293)\t1\n",
      "  (0, 10123)\t2\n",
      "  (0, 9545)\t1\n",
      "  (0, 23450)\t1\n",
      "  (0, 9619)\t1\n",
      "  (0, 18876)\t1\n",
      "  (0, 9046)\t1\n",
      "  (0, 6936)\t1\n",
      "  (0, 17430)\t1\n",
      "  (0, 4681)\t1\n",
      "  (0, 13717)\t2\n",
      "  (0, 28521)\t1\n",
      "  (0, 25033)\t1\n",
      "  (0, 7014)\t2\n",
      "  (0, 8048)\t1\n",
      "  (0, 21230)\t1\n",
      "  (0, 19513)\t1\n",
      "  (0, 24535)\t1\n",
      "  (0, 25976)\t1\n",
      "  (0, 8519)\t1\n",
      "  (0, 4639)\t1\n",
      "  (0, 13348)\t1\n",
      "  (0, 20740)\t1\n",
      "  (0, 10253)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorized = CountVectorizer().fit_transform(data_train.data)\n",
    "\n",
    "print(vectorized.shape)\n",
    "print(\"Sample record, after transformation:\")\n",
    "print(vectorized[example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use this `CountVectorizer` as part of a pipeline to predict the target field (newsgroup category) based on the text input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       408\n",
      "           1       0.88      0.90      0.89       384\n",
      "           2       0.88      0.90      0.89       390\n",
      "\n",
      "    accuracy                           0.90      1182\n",
      "   macro avg       0.90      0.90      0.90      1182\n",
      "weighted avg       0.90      0.90      0.90      1182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('sgd', SGDClassifier()),\n",
    "])\n",
    "pipeline.fit(data_train.data, data_train.target)\n",
    "\n",
    "\n",
    "# select test set to assess the quality of our model\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "print(classification_report(pipeline.predict(data_test.data), data_test.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting up this base pipeline, let's create an additional transformation step that leverages iKnow to get rid of all negated sentence spans. We'll first create a `strip_negation()` method similar to the `highlight()` method above, and then use it in a Transformer class implementing the appropriate sklearn interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import iknowpy\n",
    "\n",
    "\n",
    "def strip_negation(text, language=\"en\", iknow=iknowpy.iKnowEngine()):\n",
    "    \n",
    "    iknow.index(text, language)\n",
    "    stripped = \"\"\n",
    "\n",
    "    for s in iknow.m_index['sentences']:\n",
    "        \n",
    "        # first figure out where negation spans are and tag those entities\n",
    "        for a in s['path_attributes']:\n",
    "            \n",
    "            # path attributes are expressed as positions within s['path'],\n",
    "            # which in turn keys into the s['entities'] array\n",
    "            if a['type']==\"Negation\":\n",
    "                for ent in range(s['path'][a['pos']], \n",
    "                                 s['path'][a['pos']+a['span']-1]+1):\n",
    "                    s['entities'][ent]['neg'] = 1\n",
    "                    \n",
    "        for e in s['entities']:\n",
    "            if \"neg\" in e:\n",
    "                continue\n",
    "            stripped += text[e['offset_start']:e['offset_stop']] + \" \"\n",
    "\n",
    "    return stripped\n",
    "\n",
    "\n",
    "# implement sklearn Transformation interface\n",
    "class iKnowNegationStripper(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, language = \"en\"):\n",
    "        self.engine = iknowpy.iKnowEngine()\n",
    "        self.language = language\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        X_ = []\n",
    "        for source_text in X:\n",
    "            X_.append(strip_negation(source_text, self.language, self.engine))\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new Transformer can now be included at the start of the pipeline to build the model anew. For this particular (public) dataset, the difference in accuracy is very small, but in other datasets where negation (or any of the other attributes iKnow detects) is more important with respect to the target field, the uptick in precision can be more substantial. Other approaches included not leaving the attributed entities out, but rather flagging them with a suffix so they end up as separate features after the `CountVectorizer` transfomation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93       412\n",
      "           1       0.92      0.92      0.92       397\n",
      "           2       0.89      0.94      0.91       373\n",
      "\n",
      "    accuracy                           0.92      1182\n",
      "   macro avg       0.92      0.92      0.92      1182\n",
      "weighted avg       0.92      0.92      0.92      1182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline2 = Pipeline([\n",
    "    ('ik', iKnowNegationStripper()),\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('sgd', SGDClassifier()),\n",
    "])\n",
    "\n",
    "pipeline2.fit(data_train.data, data_train.target)\n",
    "\n",
    "print(classification_report(pipeline2.predict(data_test.data), data_test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
